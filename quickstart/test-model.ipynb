{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットを読み込む"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST データセットを読み込んで準備します。ここではサンプルデータを整数から浮動小数点数に変換します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 6s 1us/step\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test= x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習モデルを構築"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "層を積み重ねてtk.keras.Sequentialモデルを構築します。訓練のためにオプティマイザと損失関数を選びます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各サンプルについて、モデルは \"logits\" または \"log-odds\" スコアのベクトルをクラスごとに返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.37404287,  0.1738635 ,  0.7010235 , -0.28596538,  0.29389548,\n",
       "        -0.53192556,  0.1974236 , -0.29049873,  0.21751311,  0.4252373 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.nn.softmax関数は、クラスごとにこれらのロジットを\"probabilities\"に変換します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12034305, 0.09851088, 0.1668887 , 0.06219895, 0.11107427,\n",
       "        0.04863668, 0.10085937, 0.06191762, 0.10290608, 0.12666439]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意: この tf.nn.softmax をネットワークの最後のレイヤーのアクティベーション関数として組み込むことも可能です。こうすることでモデルの出力をより直接的に解釈可能にすることもできますが、softmax 出力を使用する場合、すべてのモデルに対して正確で数値的に安定した損失計算を提供することは不可能であるため、この方法は推奨されません。\n",
    "\n",
    "losses.SparseCategoricalCrossentropy 損失は、ロジットのベクトルと True インデックスを取り、各サンプルのスカラー損失を返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この損失は、True のクラスの負の対数確率に等しくなります。モデルが正しいクラスであることが確実な場合はゼロです。\n",
    "\n",
    "トレーニングされていないこのモデルでは、ランダムに近い確率（クラス当たり 1/10）が得られるため、最初の損失は -tf.math.log(1/10) ~= 2.3 に近くなります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0233772"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トレーニングを開始する前に、Keras Model.compile を使用してモデルの構成とコンパイルを行います。optimizer クラスを adam に、loss を前に定義した loss_fn 関数に設定し、metrics パラメータを accuracy に設定して評価するモデルの指標を指定します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルをトレーニングして評価する<br>\n",
    "損失を最小限に抑えられるようにモデルのパラメータを Model.fit メソッドで調整します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 10:38:14.881994: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2896 - accuracy: 0.9164\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1381 - accuracy: 0.9586\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1028 - accuracy: 0.9688\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0825 - accuracy: 0.9750\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0695 - accuracy: 0.9781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16d7b3bb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model.evaluateメソッドは通常、検証セットがテストセットでモデルパフォーマンスをチェックします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.0786 - accuracy: 0.9763 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07862693816423416, 0.9763000011444092]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.nn.softmax関数はクラスごとにこれらのロジットを\"確率\"に変換します<br>\n",
    "\n",
    "モデルが確率で返すようにするには、トレーニング済みのモデルをラップして、それに<br>\n",
    "softmaxを接続することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "    model,\n",
    "    tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[6.7872480e-07, 1.0933553e-09, 3.4200108e-05, 8.4373190e-05,\n",
       "        2.3258274e-11, 1.8068009e-06, 1.3558508e-12, 9.9987376e-01,\n",
       "        1.6393303e-06, 3.5846172e-06],\n",
       "       [2.0656280e-07, 5.1188137e-04, 9.9941349e-01, 4.2385112e-05,\n",
       "        5.6106890e-14, 5.8181040e-06, 9.0223261e-07, 6.5415872e-12,\n",
       "        2.5293113e-05, 8.7589641e-10],\n",
       "       [6.0043394e-06, 9.9722242e-01, 4.4351071e-04, 1.5435258e-05,\n",
       "        6.2558785e-05, 3.8697508e-05, 8.9834211e-05, 1.4575985e-03,\n",
       "        6.5622188e-04, 7.6980878e-06],\n",
       "       [9.9999094e-01, 4.8797126e-13, 4.8989687e-06, 3.5379299e-09,\n",
       "        2.1640219e-09, 4.7373831e-08, 2.0220796e-06, 6.9776922e-07,\n",
       "        2.8125875e-09, 1.3498915e-06],\n",
       "       [4.6314428e-05, 6.6259481e-10, 3.1578606e-05, 4.9689568e-08,\n",
       "        9.8219299e-01, 1.2290172e-07, 8.8333593e-07, 4.9104512e-04,\n",
       "        6.5099704e-07, 1.7236371e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model(x_test[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
